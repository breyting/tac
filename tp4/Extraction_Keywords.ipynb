{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports et setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yake\n",
    "\n",
    "# Instantier l'extracteur de mots clés\n",
    "kw_extractor = yake.KeywordExtractor(lan=\"fr\", top=50)\n",
    "kw_extractor\n",
    "\n",
    "txt_path = \"D:\\_COURS\\TAC\\Camille_Israel_AND_Palestine\"\n",
    "files = [f for f in os.listdir(txt_path)]\n",
    "\n",
    "txt_path_clean = \"../data/txt_clean/\"\n",
    "files_cleaned = [f for f in os.listdir(txt_path_clean)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction des Keywords des textes de bases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction classique par document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in sorted(files)[:20]:\n",
    "    text = open(os.path.join(txt_path, f), 'r', encoding=\"utf-8\").read()\n",
    "    keywords = kw_extractor.extract_keywords(text)\n",
    "    kept = []\n",
    "    for kw, score in keywords:\n",
    "        words = kw.split()\n",
    "        if len(words) == 2:\n",
    "            kept.append(kw)\n",
    "    print(f\"{f} mentions these keywords: {', '.join(kept)}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction des keywords qui reviennent chaque année."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [1948, 1949, 1950]\n",
    "\n",
    "for year in years:\n",
    "    txts = [f for f in os.listdir(txt_path) if os.path.isfile(os.path.join(txt_path, f)) and str(year) in f]\n",
    "    year_keywords = []  # List to store keywords for the current year\n",
    "    for txt in txts:\n",
    "        text = open(os.path.join(txt_path, txt), 'r', encoding=\"utf-8\").read()\n",
    "        keywords = kw_extractor.extract_keywords(text)\n",
    "        kept = []\n",
    "        for kw, score in keywords:\n",
    "            words = kw.split()\n",
    "            if len(words) == 2:\n",
    "                kept.append(kw)\n",
    "        year_keywords.extend(kept)  # Add keywords of current text to the year_keywords list\n",
    "    \n",
    "    # Write the year_keywords list to a text file\n",
    "    with open(f\"keywords_{year}.txt\", \"w\") as file:\n",
    "        file.write(\"\\n\".join(year_keywords))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keywords_1948.txt mentions these keywords: Libre Belgique, plan Marshall, comte Bernadotte, Parti Communiste, Berlin Berlin, Etats arabes, Affaires étrangères, président Truman, Etat juif, zone soviétique, commission politique, JOURNAL QUOTIDIEN, secteur soviétique, soviétique Berlin, Gouvernement soviétique...\n",
      "keywords_1949.txt mentions these keywords: Libre Belgique, Pacte Atlantique, Parti communiste, JOURNAL QUOTIDIEN, Affaires étrangères, président Truman, plan Marshall, gouvernement britannique, QUOTIDIEN TELEPHONES, Parti Socialiste, Foreign Office, cardinal Mindszenty, Londres Londres, Partis Communistes...\n",
      "keywords_1950.txt mentions these keywords: LIBRE BELGIQUE, Léopold III, président Truman, parti communiste, Van Zeeland, Ligue arabe, Affaires étrangères, roi Léopold, plan Marshall, MAC ARTHUR, cours d'une, Trygve Lie, pays arabes...\n"
     ]
    }
   ],
   "source": [
    "new_files = [\"keywords_1948.txt\", \"keywords_1949.txt\", \"keywords_1950.txt\"]\n",
    "for f in new_files:\n",
    "    text = open(f, 'r').read()\n",
    "    keywords = kw_extractor.extract_keywords(text)\n",
    "    kept = []\n",
    "    for kw, score in keywords:\n",
    "        words = kw.split()\n",
    "        if len(words) == 2:\n",
    "            kept.append(kw)\n",
    "    print(f\"{f} mentions these keywords: {', '.join(kept)}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction des keywords des text_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in sorted(files)[:20]:\n",
    "    text = open(os.path.join(txt_path_clean, f), 'r', encoding=\"utf-8\").read()\n",
    "    keywords = kw_extractor.extract_keywords(text)\n",
    "    kept = []\n",
    "    for kw, score in keywords:\n",
    "        words = kw.split()\n",
    "        if len(words) == 2:\n",
    "            kept.append(kw)\n",
    "    print(f\"{f} mentions these keywords: {', '.join(kept)}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction des keywords qui reviennent chaque année."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [1948, 1949, 1950]\n",
    "\n",
    "for year in years:\n",
    "    txts = [f for f in os.listdir(txt_path_clean) if os.path.isfile(os.path.join(txt_path_clean, f)) and str(year) in f]\n",
    "    year_keywords = []  # List to store keywords for the current year\n",
    "    for txt in txts:\n",
    "        text = open(os.path.join(txt_path_clean, txt), 'r', encoding=\"utf-8\").read()\n",
    "        keywords = kw_extractor.extract_keywords(text)\n",
    "        kept = []\n",
    "        for kw, score in keywords:\n",
    "            words = kw.split()\n",
    "            if len(words) == 2:\n",
    "                kept.append(kw)\n",
    "        year_keywords.extend(kept)  # Add keywords of current text to the year_keywords list\n",
    "    \n",
    "    # Write the year_keywords list to a text file\n",
    "    with open(f\"keywords_clean_{year}.txt\", \"w\") as file:\n",
    "        file.write(\"\\n\".join(year_keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keywords_clean_1948.txt mentions these keywords: comte Bernadotte, Etats arabes, Etat juif, LIGUE ARABE, l'Etat d'Israël, Légion arabe, Etat d'Israël, Jérusalem Jérusalem, Etat arabe, arabes arabes, nouvel Etat, GOUVERNEMENT D'ISRAËL, l'Etat juif, arabe arabe, Palestine arabe, d'Israël d'Israël, arabe comte...\n",
      "keywords_clean_1949.txt mentions these keywords: Etats arabes, l'Etat d'Israël, Nations Unies, Lieux Saints, Gouvernement d'Israël, Ligue Arabe, Palestine arabe, Légion arabe, Etat d'Israël, LIBRE BELGIQUE, Lake Success, gouvernement israélien, Ralph Bunche, Foreign Office, Etat Juif, Gouvernement britannique, arabe arabe, d'une d'une, d'Israël gouvernement, pays arabes, Palestine Israël, réfugiés arabes, troupes britanniques, d'Israël d'Israël, nouvel Etat...\n",
      "keywords_clean_1950.txt mentions these keywords: Ligue Arabe, Palestine arabe, pays arabes, Etats arabes, monde arabe, l'Etat d'Israël, d'une d'une, Jérusalem arabe, arabe arabe, partie arabe, arabe gouvernement, Israël Jérusalem, réfugiés arabes, Azzam Pacha, Israël pourront, arabes arabes, roi Abdullah, Cour arabe, arabe pays, Nations Unies...\n"
     ]
    }
   ],
   "source": [
    "new_files = [\"keywords_clean_1948.txt\", \"keywords_clean_1949.txt\", \"keywords_clean_1950.txt\"]\n",
    "for f in new_files:\n",
    "    text = open(f, 'r').read()\n",
    "    keywords = kw_extractor.extract_keywords(text)\n",
    "    kept = []\n",
    "    for kw, score in keywords:\n",
    "        words = kw.split()\n",
    "        if len(words) == 2:\n",
    "            kept.append(kw)\n",
    "    print(f\"{f} mentions these keywords: {', '.join(kept)}...\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tac_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
